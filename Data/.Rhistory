#count positive, negative, uncertainty, litigious, constraining words
positive_num = nrow(filter(tidy_speech, sentiment == "positive")) #perfect
negative_num = nrow(filter(tidy_speech, sentiment == "negative"))
uncertainty_num = nrow(filter(tidy_speech, sentiment == "uncertainty"))
litigious_num = nrow(filter(tidy_speech, sentiment == "litigious"))
constraining_num = nrow(filter(tidy_speech, sentiment == "constraining"))
#Add to exisiting dataframe:
sentiment_df = rbind(sentiment_df, data.frame(date, as.integer(positive_num), as.integer(negative_num),
as.integer(uncertainty_num), as.integer(litigious_num),
as.integer(constraining_num)))
}
sentiment_df
sentiment_df(names) = c(positive_num,negative_num, uncertainty_num, litigious_num, constraining_num)
names(sentiment_df) = c(positive_num,negative_num, uncertainty_num, litigious_num, constraining_num)
str(sentiment_df)
head(sentiment_df)
files = list.files(getwd())
#create a dataframe to store results
sentiment_df = NULL
#loughran sentiment
sentiments = get_sentiments("loughran")
for (i in files)
{
#date is the first four letters of file name.
date = substr(i,1,4)
#read in text and prepare for analysis
text = as_tibble(read.delim(i, header = FALSE, stringsAsFactors = FALSE))
text_df = mutate(text, line_number = row_number())
names(text_df) = c("text", "line_number")
text_df = as_tibble(text_df)
tidy_speech = text_df %>% unnest_tokens(word,text)
#remove stopwords
tidy_speech = tidy_speech %>% anti_join(stop_words)
#use loughran to gauge sentiment:
tidy_speech = inner_join(tidy_speech, sentiments)
#count positive, negative, uncertainty, litigious, constraining words
positive_num = nrow(filter(tidy_speech, sentiment == "positive")) #perfect
negative_num = nrow(filter(tidy_speech, sentiment == "negative"))
uncertainty_num = nrow(filter(tidy_speech, sentiment == "uncertainty"))
litigious_num = nrow(filter(tidy_speech, sentiment == "litigious"))
constraining_num = nrow(filter(tidy_speech, sentiment == "constraining"))
#Add to exisiting dataframe:
sentiment_df = rbind(sentiment_df, data.frame(date, as.integer(positive_num), as.integer(negative_num),
as.integer(uncertainty_num), as.integer(litigious_num),
as.integer(constraining_num)))
}
names(sentiment_df) = c(positive_num,negative_num, uncertainty_num, litigious_num, constraining_num)
head(sentiment_df)
sentiment_df = NULL
#loughran sentiment
sentiments = get_sentiments("loughran")
for (i in files)
{
#date is the first four letters of file name.
date = substr(i,1,4)
#read in text and prepare for analysis
text = as_tibble(read.delim(i, header = FALSE, stringsAsFactors = FALSE))
text_df = mutate(text, line_number = row_number())
names(text_df) = c("text", "line_number")
text_df = as_tibble(text_df)
tidy_speech = text_df %>% unnest_tokens(word,text)
#remove stopwords
tidy_speech = tidy_speech %>% anti_join(stop_words)
#use loughran to gauge sentiment:
tidy_speech = inner_join(tidy_speech, sentiments)
#count positive, negative, uncertainty, litigious, constraining words
positive_num = nrow(filter(tidy_speech, sentiment == "positive")) #perfect
negative_num = nrow(filter(tidy_speech, sentiment == "negative"))
uncertainty_num = nrow(filter(tidy_speech, sentiment == "uncertainty"))
litigious_num = nrow(filter(tidy_speech, sentiment == "litigious"))
constraining_num = nrow(filter(tidy_speech, sentiment == "constraining"))
#Add to exisiting dataframe:
sentiment_df = rbind(sentiment_df, data.frame(as.date(date), as.integer(positive_num), as.integer(negative_num),
as.integer(uncertainty_num), as.integer(litigious_num),
as.integer(constraining_num)))
}
names(sentiment_df) = c(positive_num,negative_num, uncertainty_num, litigious_num, constraining_num)
files = list.files(getwd())
#create a dataframe to store results
sentiment_df = NULL
#loughran sentiment
sentiments = get_sentiments("loughran")
for (i in files)
{
#date is the first four letters of file name.
date = substr(i,1,4)
#read in text and prepare for analysis
text = as_tibble(read.delim(i, header = FALSE, stringsAsFactors = FALSE))
text_df = mutate(text, line_number = row_number())
names(text_df) = c("text", "line_number")
text_df = as_tibble(text_df)
tidy_speech = text_df %>% unnest_tokens(word,text)
#remove stopwords
tidy_speech = tidy_speech %>% anti_join(stop_words)
#use loughran to gauge sentiment:
tidy_speech = inner_join(tidy_speech, sentiments)
#count positive, negative, uncertainty, litigious, constraining words
positive_num = nrow(filter(tidy_speech, sentiment == "positive")) #perfect
negative_num = nrow(filter(tidy_speech, sentiment == "negative"))
uncertainty_num = nrow(filter(tidy_speech, sentiment == "uncertainty"))
litigious_num = nrow(filter(tidy_speech, sentiment == "litigious"))
constraining_num = nrow(filter(tidy_speech, sentiment == "constraining"))
#Add to exisiting dataframe:
sentiment_df = rbind(sentiment_df, data.frame(as.Date(date), as.integer(positive_num), as.integer(negative_num),
as.integer(uncertainty_num), as.integer(litigious_num),
as.integer(constraining_num)))
}
names(sentiment_df) = c(positive_num,negative_num, uncertainty_num, litigious_num, constraining_num)
sentiment_df = NULL
#loughran sentiment
sentiments = get_sentiments("loughran")
for (i in files)
{
#date is the first four letters of file name.
date = paste(substr(i,3,4),substr(i,3,4), sep ="")
#read in text and prepare for analysis
text = as_tibble(read.delim(i, header = FALSE, stringsAsFactors = FALSE))
text_df = mutate(text, line_number = row_number())
names(text_df) = c("text", "line_number")
text_df = as_tibble(text_df)
tidy_speech = text_df %>% unnest_tokens(word,text)
#remove stopwords
tidy_speech = tidy_speech %>% anti_join(stop_words)
#use loughran to gauge sentiment:
tidy_speech = inner_join(tidy_speech, sentiments)
#count positive, negative, uncertainty, litigious, constraining words
positive_num = nrow(filter(tidy_speech, sentiment == "positive")) #perfect
negative_num = nrow(filter(tidy_speech, sentiment == "negative"))
uncertainty_num = nrow(filter(tidy_speech, sentiment == "uncertainty"))
litigious_num = nrow(filter(tidy_speech, sentiment == "litigious"))
constraining_num = nrow(filter(tidy_speech, sentiment == "constraining"))
#Add to exisiting dataframe:
sentiment_df = rbind(sentiment_df, data.frame(as.Date(date), as.integer(positive_num), as.integer(negative_num),
as.integer(uncertainty_num), as.integer(litigious_num),
as.integer(constraining_num)))
}
names(sentiment_df) = c(positive_num,negative_num, uncertainty_num, litigious_num, constraining_num)
sentiment_df = (date = as.Date(), positive_num = as.integer(), negative_num = as.integer(),
uncertainty_num = as.integer(), litigious_num = as.integer(),constraining_num = as.integer())
sentiment_df = (date = Date(), positive_num = integer(), negative_num = integer(),
uncertainty_num = integer(), litigious_num = integer(), constraining_num = integer())
sentiment_df = data.frame(date = Date(), positive_num = integer(), negative_num = integer(),
uncertainty_num = integer(), litigious_num = integer(), constraining_num = integer())
sentiment_df = data.frame(date = date(), positive_num = integer(), negative_num = integer(),
uncertainty_num = integer(), litigious_num = integer(), constraining_num = integer())
sentiment_df = data.frame(date = character(), positive_num = integer(), negative_num = integer(),
uncertainty_num = integer(), litigious_num = integer(), constraining_num = integer())
sentiments = get_sentiments("loughran")
sentiment_df
for (i in files)
{
#date is the first four letters of file name.
date = paste(substr(i,3,4),substr(i,3,4), sep ="")
#read in text and prepare for analysis
text = as_tibble(read.delim(i, header = FALSE, stringsAsFactors = FALSE))
text_df = mutate(text, line_number = row_number())
names(text_df) = c("text", "line_number")
text_df = as_tibble(text_df)
tidy_speech = text_df %>% unnest_tokens(word,text)
#remove stopwords
tidy_speech = tidy_speech %>% anti_join(stop_words)
#use loughran to gauge sentiment:
tidy_speech = inner_join(tidy_speech, sentiments)
#count positive, negative, uncertainty, litigious, constraining words
positive_num = nrow(filter(tidy_speech, sentiment == "positive")) #perfect
negative_num = nrow(filter(tidy_speech, sentiment == "negative"))
uncertainty_num = nrow(filter(tidy_speech, sentiment == "uncertainty"))
litigious_num = nrow(filter(tidy_speech, sentiment == "litigious"))
constraining_num = nrow(filter(tidy_speech, sentiment == "constraining"))
#Add to exisiting dataframe:
sentiment_df = rbind(sentiment_df, data.frame(as.Date(date), as.integer(positive_num), as.integer(negative_num),
as.integer(uncertainty_num), as.integer(litigious_num),
as.integer(constraining_num)))
}
for (i in files)
{
#date is the first four letters of file name.
date = paste(substr(i,3,4),substr(i,1,2), sep ="")
#read in text and prepare for analysis
text = as_tibble(read.delim(i, header = FALSE, stringsAsFactors = FALSE))
text_df = mutate(text, line_number = row_number())
names(text_df) = c("text", "line_number")
text_df = as_tibble(text_df)
tidy_speech = text_df %>% unnest_tokens(word,text)
#remove stopwords
tidy_speech = tidy_speech %>% anti_join(stop_words)
#use loughran to gauge sentiment:
tidy_speech = inner_join(tidy_speech, sentiments)
#count positive, negative, uncertainty, litigious, constraining words
positive_num = nrow(filter(tidy_speech, sentiment == "positive")) #perfect
negative_num = nrow(filter(tidy_speech, sentiment == "negative"))
uncertainty_num = nrow(filter(tidy_speech, sentiment == "uncertainty"))
litigious_num = nrow(filter(tidy_speech, sentiment == "litigious"))
constraining_num = nrow(filter(tidy_speech, sentiment == "constraining"))
#Add to exisiting dataframe:
sentiment_df = rbind(sentiment_df, data.frame(as.Date(date), as.integer(positive_num), as.integer(negative_num),
as.integer(uncertainty_num), as.integer(litigious_num),
as.integer(constraining_num)))
}
sentiment_df = data.frame(date = character(), positive_num = integer(), negative_num = integer(),
uncertainty_num = integer(), litigious_num = integer(), constraining_num = integer())
#loughran sentiment
sentiments = get_sentiments("loughran")
for (i in files)
{
#date is the first four letters of file name.
date = paste(substr(i,3,4),substr(i,1,2), sep ="")
#read in text and prepare for analysis
text = as_tibble(read.delim(i, header = FALSE, stringsAsFactors = FALSE))
text_df = mutate(text, line_number = row_number())
names(text_df) = c("text", "line_number")
text_df = as_tibble(text_df)
tidy_speech = text_df %>% unnest_tokens(word,text)
#remove stopwords
tidy_speech = tidy_speech %>% anti_join(stop_words)
#use loughran to gauge sentiment:
tidy_speech = inner_join(tidy_speech, sentiments)
#count positive, negative, uncertainty, litigious, constraining words
positive_num = nrow(filter(tidy_speech, sentiment == "positive")) #perfect
negative_num = nrow(filter(tidy_speech, sentiment == "negative"))
uncertainty_num = nrow(filter(tidy_speech, sentiment == "uncertainty"))
litigious_num = nrow(filter(tidy_speech, sentiment == "litigious"))
constraining_num = nrow(filter(tidy_speech, sentiment == "constraining"))
#Add to exisiting dataframe:
sentiment_df = rbind(sentiment_df, data.frame(date, as.integer(positive_num), as.integer(negative_num),
as.integer(uncertainty_num), as.integer(litigious_num),
as.integer(constraining_num)))
}
sentiment_df
head(sentiment_df)
names(sentiment_df) = c(date, positive, negative, uncertain, litigious, constraining)
names(sentiment_df) = c("date", "positive", "negative", "uncertain", "litigious", "constraining")
head(sentiment_df)
str(sentiment_df)
sentiment_df$date = as.Date(sentiment_df$date, "%m%y")
str(sentiment_df)
sentiment_df = data.frame(date = character(), positive_num = integer(), negative_num = integer(),
uncertainty_num = integer(), litigious_num = integer(), constraining_num = integer())
#loughran sentiment
sentiments = get_sentiments("loughran")
for (i in files)
{
#date is the first four letters of file name.
date = paste("01",substr(i,3,4),substr(i,1,2), sep ="")
#read in text and prepare for analysis
text = as_tibble(read.delim(i, header = FALSE, stringsAsFactors = FALSE))
text_df = mutate(text, line_number = row_number())
names(text_df) = c("text", "line_number")
text_df = as_tibble(text_df)
tidy_speech = text_df %>% unnest_tokens(word,text)
#remove stopwords
tidy_speech = tidy_speech %>% anti_join(stop_words)
#use loughran to gauge sentiment:
tidy_speech = inner_join(tidy_speech, sentiments)
#count positive, negative, uncertainty, litigious, constraining words
positive_num = nrow(filter(tidy_speech, sentiment == "positive")) #perfect
negative_num = nrow(filter(tidy_speech, sentiment == "negative"))
uncertainty_num = nrow(filter(tidy_speech, sentiment == "uncertainty"))
litigious_num = nrow(filter(tidy_speech, sentiment == "litigious"))
constraining_num = nrow(filter(tidy_speech, sentiment == "constraining"))
#Add to exisiting dataframe:
sentiment_df = rbind(sentiment_df, data.frame(date, as.integer(positive_num), as.integer(negative_num),
as.integer(uncertainty_num), as.integer(litigious_num),
as.integer(constraining_num)))
}
names(sentiment_df) = c("date", "positive", "negative", "uncertain", "litigious", "constraining")
str(sentiment_df)
sentiment_df$date = as.Date(sentiment_df$date, "%d%m%y")
head(sentiment_df)
positive_chart = ggplot(aes(date,positive)) +
geom_line()
positive_chart = ggplot(sentiment_df, aes(date,positive)) +
geom_line()
positive_chart
negative_chart = ggplot(sentiment_df, aes(date,negative)) + geom_line()
sentiment_df = mutate(sentiment_df, difference = positive-negative)
difference_chart = ggplot(sentiment_df, aes(date,difference)) + geom_line()
negative_chart
difference_chart
for (i in files)
{
#date is the first four letters of file name.
date = paste("01",substr(i,3,4),substr(i,1,2), sep ="")
#read in text and prepare for analysis
text = as_tibble(read.delim(i, header = FALSE, stringsAsFactors = FALSE))
text_df = mutate(text, line_number = row_number())
names(text_df) = c("text", "line_number")
text_df = as_tibble(text_df)
tidy_speech = text_df %>% unnest_tokens(word,text)
#remove stopwords
tidy_speech = tidy_speech %>% anti_join(stop_words)
#use loughran to gauge sentiment:
tidy_speech = inner_join(tidy_speech, sentiments)
#count positive, negative, uncertainty, litigious, constraining words
positive_num = nrow(filter(tidy_speech, sentiment == "positive")) #perfect
negative_num = nrow(filter(tidy_speech, sentiment == "negative"))
uncertainty_num = nrow(filter(tidy_speech, sentiment == "uncertainty"))
litigious_num = nrow(filter(tidy_speech, sentiment == "litigious"))
constraining_num = nrow(filter(tidy_speech, sentiment == "constraining"))
#Add to exisiting dataframe:
sentiment_df = rbind(sentiment_df, data.frame(date, as.integer(positive_num), as.integer(negative_num),
as.integer(uncertainty_num), as.integer(litigious_num),
as.integer(constraining_num)))
}
files = list.files(getwd())
#create a dataframe to store results
sentiment_df = data.frame(date = character(), positive_num = integer(), negative_num = integer(),
uncertainty_num = integer(), litigious_num = integer(), constraining_num = integer())
#loughran sentiment
sentiments = get_sentiments("loughran")
for (i in files)
{
#date is the first four letters of file name.
date = paste("01",substr(i,3,4),substr(i,1,2), sep ="")
#read in text and prepare for analysis
text = as_tibble(read.delim(i, header = FALSE, stringsAsFactors = FALSE))
text_df = mutate(text, line_number = row_number())
names(text_df) = c("text", "line_number")
text_df = as_tibble(text_df)
tidy_speech = text_df %>% unnest_tokens(word,text)
#remove stopwords
tidy_speech = tidy_speech %>% anti_join(stop_words)
#use loughran to gauge sentiment:
tidy_speech = inner_join(tidy_speech, sentiments)
#count positive, negative, uncertainty, litigious, constraining words
positive_num = nrow(filter(tidy_speech, sentiment == "positive")) #perfect
negative_num = nrow(filter(tidy_speech, sentiment == "negative"))
uncertainty_num = nrow(filter(tidy_speech, sentiment == "uncertainty"))
litigious_num = nrow(filter(tidy_speech, sentiment == "litigious"))
constraining_num = nrow(filter(tidy_speech, sentiment == "constraining"))
#Add to exisiting dataframe:
sentiment_df = rbind(sentiment_df, data.frame(date, as.integer(positive_num), as.integer(negative_num),
as.integer(uncertainty_num), as.integer(litigious_num),
as.integer(constraining_num)))
}
names(sentiment_df) = c("date", "positive", "negative", "uncertain", "litigious", "constraining")
head(get_sentiments("loughran"))
positive_chart = ggplot(sentiment_df, aes(date,positive)) + geom_line()
positive_chart
negative_chart = ggplot(sentiment_df, aes(date,negative)) + geom_line()
negative_chart
sentiment_df$date = as.Date(sentiment_df$date, "%d%m%y")
sentiment_df = mutate(sentiment_df, difference = positive-negative)
positive_chart = ggplot(sentiment_df, aes(date,positive)) + geom_line()
positive_chart
negative_chart = ggplot(sentiment_df, aes(date,negative)) + geom_line()
negative_chart
difference_chart = ggplot(sentiment_df, aes(date,difference)) + geom_line()
difference_chart
library(dplyr)
library(lubridate)
library(ggplot2)
library(forecast)
library(zoo)
setwd("/Users/Jake/Projects/RBARetailSales/Data/")
data = read.csv("RBARetailSales.csv")
#rename headings
names(data) = c("Per_Capita_Current", "Per_Capita_Current_2", "Per_Capita_Current_3", "Per_Capita_Current_Chain_1", "Per_Capita_Current_Chain_2", "Per_Capita_Current_Chain_3")
data = select(data, Date, Per_Capita_Current)
myts = select(data,Per_Capita_Current)
myts = ts(myts, frequency = 4, start = c(1983,3))
plot.ts(myts)
rba_retail_sales_components <- decompose(myts)
plot(rba_retail_sales_components)
rba_forecasts <- HoltWinters(myts)
#Predicts 8 quarters into the future.
rba_future <- forecast.HoltWinters(rba_forecasts, h=8)
plot.forecast(rba_future)
#Plot Individual Components of Retail Sales:
industry_data = read.csv("SalesByIndustry.csv", stringsAsFactors = FALSE)
industry_data = industry_data[-c(1,2,3,4,5,6,7,8,9,10), c(1,2,3,4,5,6,7,8)]
names(industry_data) = c("Date", "Food_Retailing", "Household_Goods", "Clothing_Footwear", "Department_Stores", "Other", "Cafes_Restaurants",
"Total")
industry_data$Date = paste0("01-",industry_data$Date)
industry_data$Date = dmy(industry_data$Date)
#Change all columns to numeric
industry_data[-1] <- lapply(industry_data[-1], as.numeric)
# labels and breaks for X axis text
#brks <- industry_data$Date[seq(1, length(industry_data$Date), 12)]
#lbls <- lubridate::year(brks)
#Plotting first:
abs_retail_sales = ggplot(industry_data, aes(x=Date)) +
geom_line(aes(y=Food_Retailing, col="Food_Retailing")) +
geom_line(aes(y=Household_Goods, col = "Household_Goods")) +
geom_line(aes(y=Clothing_Footwear, col = "Clothing_Footwear")) +
geom_line(aes(y=Department_Stores, col = "Department_Stores")) +
geom_line(aes(y=Other, col = "Other")) +
geom_line(aes(y=Cafes_Restaurants, col = "Cafes_Restaurants")) +
labs(title="ABS Retail Sales",
caption="Source: ABS, jakebowmer.com", y="Dollar, Millions") +
scale_color_manual(name="",
values = c("Food_Retailing"="red", "Household_Goods"="blue", "Clothing_Footwear" = "green",
"Department_Stores" = "yellow", "Other" = "grey", "Cafes_Restaurants" = "black"))
#Now a chart for total as a time series.
myts = select(industry_data,Total)
myts = ts(myts, frequency = 12, start = c(1982,5))
autoplot(myts)
abs_retail_sales_components <- decompose(myts)
autoplot(rba_retail_sales_components)
abs_forecasts <- HoltWinters(myts)
#Predicts 8 quarters into the future.
abs_future <- forecast.HoltWinters(abs_forecasts, h=8)
autoplot(abs_future)
#Trend for department stores
department_store_ts = select(industry_data,Department_Stores)
department_store_ts = ts(department_store_ts, frequency = 12, start = c(1982,5))
autoplot(department_store_ts)
department_store_components <- decompose(department_store_ts)
autoplot(department_store_components)
autoplot(department_store_components$trend) +
labs(title="ABS Department Store Trend",
caption="Source: ABS, jakebowmer.com", y = "Trend Sales")
abs_forecasts <- HoltWinters(myts)
#Predicts 8 quarters into the future.
abs_future <- forecast.HoltWinters(abs_forecasts, h=8)
autoplot(abs_future)
autoplot(department_store_components)
setwd("/Users/Jake/Projects/RBASentiment/Data")
library(tidytext)
library(dplyr)
library(tokenizers)
text = as_tibble(read.delim("1102.txt", header = FALSE, stringsAsFactors = FALSE))
text_df = mutate(text, line_number = row_number())
names(text_df) = c("text", "line_number")
text_df = as_tibble(text_df)
tidy_speech = text_df %>% unnest_tokens(word,text)
#head(tidy_speech)
#Remove stopwords
data(stop_words)
tidy_speech = tidy_speech %>% anti_join(stop_words)
#Most common words:
tidy_speech %>% count(word,sort = TRUE)
#Chart of most common words:
tidy_speech %>%
count(word, sort= TRUE) %>%
filter(n>5)%>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word,n)) +
geom_col() +
xlab(NULL) +
coord_flip()
#For sentiment, we can use either AFINN (a lexicon which assigns scores of minus 5 to plus 5) or
#use bing, which classifies as either positive or negative
#example
#head(get_sentiments("afinn"))
#For financial sentiment specifically, we use the Loughran and McDonald dictionary, which is based on financial reports.
head(get_sentiments("loughran"))
#Sentiment Analysis is an inner join operation.
sentiments = get_sentiments("loughran")
tidy_speech = inner_join(tidy_speech, sentiments)
#Now we can plot using counts
ggplot(tidy_speech, aes(sentiment)) +
geom_bar()
#What we really want to do is count the various categories,
#and assign the date of the speech and the count of each category so we can track it over time.
positive_num = nrow(filter(tidy_speech, sentiment == "positive")) #perfect
negative_num = nrow(filter(tidy_speech, sentiment == "negative"))
uncertainty_num = nrow(filter(tidy_speech, sentiment == "uncertainty"))
litigious_num = nrow(filter(tidy_speech, sentiment == "litigious"))
constraining_num = nrow(filter(tidy_speech, sentiment == "constraining"))
#Linking it all together.
#First, we read all the file names from the appropriate path
files = list.files(getwd())
#create a dataframe to store results
sentiment_df = data.frame(date = character(), positive_num = integer(), negative_num = integer(),
uncertainty_num = integer(), litigious_num = integer(), constraining_num = integer())
#loughran sentiment
sentiments = get_sentiments("loughran")
for (i in files)
{
#date is the first four letters of file name.
date = paste("01",substr(i,3,4),substr(i,1,2), sep ="")
#read in text and prepare for analysis
text = as_tibble(read.delim(i, header = FALSE, stringsAsFactors = FALSE))
text_df = mutate(text, line_number = row_number())
names(text_df) = c("text", "line_number")
text_df = as_tibble(text_df)
tidy_speech = text_df %>% unnest_tokens(word,text)
#remove stopwords
tidy_speech = tidy_speech %>% anti_join(stop_words)
#use loughran to gauge sentiment:
tidy_speech = inner_join(tidy_speech, sentiments)
#count positive, negative, uncertainty, litigious, constraining words
positive_num = nrow(filter(tidy_speech, sentiment == "positive")) #perfect
negative_num = nrow(filter(tidy_speech, sentiment == "negative"))
uncertainty_num = nrow(filter(tidy_speech, sentiment == "uncertainty"))
litigious_num = nrow(filter(tidy_speech, sentiment == "litigious"))
constraining_num = nrow(filter(tidy_speech, sentiment == "constraining"))
#Add to exisiting dataframe:
sentiment_df = rbind(sentiment_df, data.frame(date, as.integer(positive_num), as.integer(negative_num),
as.integer(uncertainty_num), as.integer(litigious_num),
as.integer(constraining_num)))
}
names(sentiment_df) = c("date", "positive", "negative", "uncertain", "litigious", "constraining")
sentiment_df$date = as.Date(sentiment_df$date, "%d%m%y")
sentiment_df = mutate(sentiment_df, difference = positive-negative)
#Now that we have our data, lets plot over time.
positive_chart = ggplot(sentiment_df, aes(date,positive)) + geom_line()
negative_chart = ggplot(sentiment_df, aes(date,negative)) + geom_line()
difference_chart = ggplot(sentiment_df, aes(date,difference)) + geom_line()
difference_chart
library(gridExtra)
grid.arrange(positive_chart, negative_chart, difference_chart, ncol = 1)
install.packages(“caret”, dependencies = c(“Depends”, “Suggests”))
install.packages(caret, dependencies = c(“Depends”, “Suggests”))
install.packages("caret")
install.packages("caret", dependenices = c("Depends", "Suggests"))
install.packages("caret", dependencies = c("Depends", "Suggests"))
install.packages("caret")
library(caret)
split = createDataPartition(a_train$poor, p = 0.75, list = FALSE)
install.packages("ModelMetrics")
